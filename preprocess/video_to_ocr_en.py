# import os
# import re
#
# import cv2
# import easyocr
# import numpy as np
# import pandas as pd
# import pytesseract
# from autocorrect import Speller
# from Levenshtein import ratio
# from skimage.metrics import structural_similarity as ssim
# from tqdm import tqdm
#
# spell = Speller(lang="en")
# reader = easyocr.Reader(["en"], gpu=True)
#
#
# def extract_frames(video_path, fps=1):
#     frames = []
#     video = cv2.VideoCapture(video_path)
#     video_fps = video.get(cv2.CAP_PROP_FPS)
#     interval = int(video_fps / fps)
#
#     frame_count = 0
#     while True:
#         ret, frame = video.read()
#         if not ret:
#             break
#         if frame_count % interval == 0:
#             frames.append(frame)
#         frame_count += 1
#
#     video.release()
#     return frames
#
#
# def frame_similarity(frame1, frame2):
#     gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
#     gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
#     score, _ = ssim(gray1, gray2, full=True)
#     return score
#
#
# def remove_similar_frames(frames, threshold=0.95):
#     if not frames:
#         return []
#
#     unique_frames = [frames[0]]
#     for i in range(1, len(frames)):
#         if frame_similarity(frames[i], frames[i - 1]) < threshold:
#             unique_frames.append(frames[i])
#     return unique_frames
#
#
# def ocr_frames(frames):
#     texts = []
#     for frame in frames:
#         text = reader.readtext(frame, detail=0)
#         text = " ".join(text)
#         # if text is not blank str
#         if text:
#             texts.append(text.strip())
#     return texts
#
#
# def remove_duplicate_texts(texts, threshold=0.7):
#     if not texts:
#         return []
#
#     unique_texts = [texts[0]]
#     for i in range(1, len(texts)):
#         if ratio(texts[i], texts[i - 1]) < threshold:
#             unique_texts.append(texts[i])
#     return unique_texts
#
#
# def clean_and_correct_text(text):
#     text = re.sub(r"[^a-zA-Z0-9\s]", "", text)
#     text = re.sub(r"\s+", " ", text)
#
#     return text.strip()
#
#     words = text.split()
#     corrected_words = []
#     for word in words:
#         if word.isupper():
#             corrected_words.append(word)
#         else:
#             corrected_words.append(spell(word))
#
#     corrected_text = " ".join(corrected_words)
#
#     return corrected_text.strip()
#
#
# def extract_text_from_video(video_path):
#     frames = extract_frames(video_path)
#     # print(f'Extracted {len(frames)} frames')
#
#     unique_frames = remove_similar_frames(frames)
#     # print(f'Removed {len(frames) - len(unique_frames)} similar frames')
#
#     texts = ocr_frames(unique_frames)
#     # print text
#     # for text in texts:
#     #     print(f'{text}')
#
#     cleaned_texts = [clean_and_correct_text(text) for text in texts]
#
#     # for text in cleaned_texts:
#     #     print(f'{text}')
#
#     unique_texts = remove_duplicate_texts(cleaned_texts)
#
#     return unique_texts
#
#
# src_dir = r"D:\code\LAB\MoREBaseline\MoRE\data\HateMM\videos\non_hate_videos"
# dst_file = r"D:\code\LAB\MoREBaseline\MoRE\data\HateMM\OCRs\OCR.jsonl"
#
# if not os.path.exists(dst_file):
#     dst_df = pd.DataFrame(columns=["vid", "ocr"])
#     dst_df.to_json(dst_file, orient="records", lines=True)
# else:
#     dst_df = pd.read_json(dst_file, lines=True)
#
# cur_ids = dst_df["vid"].values if len(dst_df) > 0 else []
#
# for file in tqdm(os.listdir(src_dir)):
#     audio_file = os.path.join(src_dir, file)
#     audio_id = file.replace(".mp4", "")
#
#     if audio_id in cur_ids:
#         continue
#
#     ocr = ""
#     result = extract_text_from_video(audio_file)
#     for text in result:
#         if len(text) > 3:
#             ocr += text + "\n"
#
#     # caption = image_to_caption(video_frames)
#     tmp_df = pd.DataFrame([{"vid": audio_id, "ocr": ocr}])
#     dst_df = pd.concat([dst_df, tmp_df], ignore_index=True)
#     dst_df.to_json(dst_file, orient="records", lines=True, force_ascii=False)

import os
import re
import cv2
import easyocr
import numpy as np
import pandas as pd
from Levenshtein import ratio
from skimage.metrics import structural_similarity as ssim
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing
import json
from functools import lru_cache
import hashlib


class VideoTextExtractor:
    def __init__(self, gpu=True, batch_size=4, num_workers=None):
        """
        åˆå§‹åŒ–æ–‡æœ¬æå–å™¨

        Args:
            gpu: æ˜¯å¦ä½¿ç”¨GPU
            batch_size: æ‰¹é‡å¤„ç†å¸§çš„æ•°é‡
            num_workers: å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
        """
        self.reader = easyocr.Reader(["en"], gpu=gpu)
        self.batch_size = batch_size

        # è‡ªåŠ¨è®¾ç½®å·¥ä½œçº¿ç¨‹æ•°
        if num_workers is None:
            self.num_workers = min(multiprocessing.cpu_count(), 8)
        else:
            self.num_workers = num_workers

        print(f"åˆå§‹åŒ–å®Œæˆ: GPU={gpu}, æ‰¹å¤§å°={batch_size}, å·¥ä½œçº¿ç¨‹={self.num_workers}")

    @staticmethod
    def extract_frames_efficient(video_path, target_fps=1):
        """
        é«˜æ•ˆæå–è§†é¢‘å¸§

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            target_fps: ç›®æ ‡å¸§ç‡ï¼ˆæ¯ç§’æå–å¤šå°‘å¸§ï¼‰
        """
        frames = []
        video = cv2.VideoCapture(video_path)

        if not video.isOpened():
            return frames

        video_fps = video.get(cv2.CAP_PROP_FPS)
        if video_fps <= 0:
            video_fps = 30  # é»˜è®¤å€¼

        # è®¡ç®—é—´éš”
        interval = max(1, int(video_fps / target_fps))

        # ä½¿ç”¨é¢„åˆ†é…å†…å­˜
        frame_count = 0
        success = True

        while success:
            success, frame = video.read()
            if not success:
                break

            if frame_count % interval == 0:
                frames.append(frame)

            frame_count += 1

            # é™åˆ¶æœ€å¤šå¤„ç†3000å¸§ï¼ˆé˜²æ­¢è¶…é•¿è§†é¢‘ï¼‰
            if frame_count > 3000:
                break

        video.release()

        # å¦‚æœå¸§å¤ªå¤šï¼Œå‡åŒ€é‡‡æ ·
        if len(frames) > 100:
            step = len(frames) // 50
            frames = frames[::step][:50]

        return frames

    @staticmethod
    def compute_frame_hash(frame):
        """è®¡ç®—å¸§çš„å“ˆå¸Œå€¼ç”¨äºå»é‡"""
        # ç¼©å°å›¾åƒä»¥åŠ é€Ÿå“ˆå¸Œè®¡ç®—
        small = cv2.resize(frame, (16, 16))
        gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
        return hashlib.md5(gray.tobytes()).hexdigest()

    def remove_similar_frames_fast(self, frames, similarity_threshold=0.9):
        """
        å¿«é€Ÿå»é™¤ç›¸ä¼¼å¸§

        Args:
            frames: å¸§åˆ—è¡¨
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        if not frames or len(frames) < 2:
            return frames

        # æ–¹æ³•1ï¼šä½¿ç”¨å“ˆå¸Œå»é‡ï¼ˆå¿«é€Ÿï¼‰
        hashes = {}
        unique_frames_hash = []

        for frame in frames:
            frame_hash = self.compute_frame_hash(frame)
            if frame_hash not in hashes:
                hashes[frame_hash] = True
                unique_frames_hash.append(frame)

        # å¦‚æœå“ˆå¸Œå»é‡åä»ç„¶å¤ªå¤šï¼Œä½¿ç”¨SSIMè¿›ä¸€æ­¥å»é‡
        if len(unique_frames_hash) > 30:
            return self.remove_similar_frames_ssim(unique_frames_hash, similarity_threshold)

        return unique_frames_hash

    @staticmethod
    def remove_similar_frames_ssim(frames, threshold=0.9):
        """ä½¿ç”¨SSIMå»é™¤ç›¸ä¼¼å¸§"""
        if not frames:
            return frames

        unique_frames = [frames[0]]
        prev_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)

        for i in range(1, len(frames)):
            gray = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)

            # ä½¿ç”¨ä¸‹é‡‡æ ·åŠ é€ŸSSIMè®¡ç®—
            if prev_gray.shape != (64, 64):
                prev_gray_small = cv2.resize(prev_gray, (64, 64))
                gray_small = cv2.resize(gray, (64, 64))
            else:
                prev_gray_small = prev_gray
                gray_small = gray

            score = ssim(prev_gray_small, gray_small)

            if score < threshold:
                unique_frames.append(frames[i])
                prev_gray = gray

        return unique_frames

    def batch_ocr_frames(self, frames):
        """
        æ‰¹é‡OCRå¤„ç†å¸§

        Args:
            frames: å¸§åˆ—è¡¨
        """
        if not frames:
            return []

        texts = []

        # æ‰¹é‡å¤„ç†
        for i in range(0, len(frames), self.batch_size):
            batch = frames[i:i + self.batch_size]

            # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡ä¸­çš„å¸§
            with ThreadPoolExecutor(max_workers=min(len(batch), 4)) as executor:
                future_to_frame = {
                    executor.submit(self._single_frame_ocr, frame): idx
                    for idx, frame in enumerate(batch)
                }

                batch_results = []
                for future in as_completed(future_to_frame):
                    try:
                        result = future.result(timeout=10)
                        if result:
                            batch_results.append(result)
                    except Exception as e:
                        print(f"OCRå¤„ç†é”™è¯¯: {e}")
                        continue

                texts.extend(batch_results)

        return texts

    def _single_frame_ocr(self, frame):
        """å•å¸§OCRå¤„ç†"""
        try:
            results = self.reader.readtext(frame, detail=0, paragraph=True)
            if results:
                text = " ".join(results).strip()
                if len(text) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                    return text
        except Exception as e:
            print(f"å¸§OCRé”™è¯¯: {e}")
        return None

    @staticmethod
    def clean_text_batch(texts):
        """æ‰¹é‡æ¸…ç†æ–‡æœ¬"""
        cleaned = []
        for text in texts:
            if not text:
                continue

            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—å’Œç©ºæ ¼
            text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
            # åˆå¹¶å¤šä¸ªç©ºæ ¼
            text = re.sub(r'\s+', ' ', text).strip()

            if len(text) > 2:
                cleaned.append(text)

        return cleaned

    @staticmethod
    def remove_duplicate_texts_fast(texts, threshold=0.7):
        """å¿«é€Ÿå»é™¤é‡å¤æ–‡æœ¬"""
        if not texts:
            return []

        unique_texts = []
        seen_hashes = set()

        for text in texts:
            if not text:
                continue

            # è®¡ç®—æ–‡æœ¬çš„ç®€å•å“ˆå¸Œï¼ˆå‰50ä¸ªå­—ç¬¦ï¼‰
            text_hash = text[:50].lower()

            # æ£€æŸ¥ç›¸ä¼¼åº¦
            is_duplicate = False
            for seen_text in unique_texts[-10:]:  # åªæ£€æŸ¥æœ€è¿‘çš„10ä¸ª
                if ratio(text.lower(), seen_text.lower()) > threshold:
                    is_duplicate = True
                    break

            if not is_duplicate and text_hash not in seen_hashes:
                unique_texts.append(text)
                seen_hashes.add(text_hash)

        return unique_texts

    def extract_text_from_video(self, video_path):
        """
        ä»è§†é¢‘ä¸­æå–æ–‡æœ¬çš„ä¸»å‡½æ•°

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            # 1. æå–å¸§
            frames = self.extract_frames_efficient(video_path, target_fps=1)
            if not frames:
                return []

            # 2. å»é™¤ç›¸ä¼¼å¸§
            unique_frames = self.remove_similar_frames_fast(frames)

            # 3. æ‰¹é‡OCR
            texts = self.batch_ocr_frames(unique_frames)

            # 4. æ¸…ç†æ–‡æœ¬
            cleaned_texts = self.clean_text_batch(texts)

            # 5. å»é‡
            final_texts = self.remove_duplicate_texts_fast(cleaned_texts)

            return final_texts

        except Exception as e:
            print(f"å¤„ç†è§†é¢‘ {video_path} æ—¶å‡ºé”™: {e}")
            return []


def process_single_video(args):
    """å¤„ç†å•ä¸ªè§†é¢‘ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
    video_path, extractor, dst_df, dst_file = args
    file_name = os.path.basename(video_path)
    video_id = os.path.splitext(file_name)[0]

    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if not dst_df.empty and video_id in dst_df["vid"].values:
        return video_id, "å·²è·³è¿‡", None

    try:
        # æå–æ–‡æœ¬
        texts = extractor.extract_text_from_video(video_path)

        # åˆå¹¶æ–‡æœ¬
        ocr_text = "\n".join([t for t in texts if len(t) > 3])

        return video_id, "æˆåŠŸ", ocr_text

    except Exception as e:
        print(f"å¤„ç†è§†é¢‘ {video_id} å¤±è´¥: {e}")
        return video_id, "å¤±è´¥", None


def main():
    # é…ç½®å‚æ•°
    src_dir = r"D:\code\LAB\MoRE2026\data\videos"
    dst_file = r"D:\code\LAB\MoRE2026\data\OCR.jsonl"

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(dst_file), exist_ok=True)

    # åˆå§‹åŒ–æå–å™¨ï¼ˆä½¿ç”¨GPUåŠ é€Ÿï¼‰
    extractor = VideoTextExtractor(gpu=True, batch_size=8, num_workers=2)

    # åŠ è½½æˆ–åˆ›å»ºæ•°æ®æ¡†
    if os.path.exists(dst_file):
        try:
            dst_df = pd.read_json(dst_file, lines=True)
            print(f"å·²åŠ è½½ {len(dst_df)} æ¡ç°æœ‰è®°å½•")
        except:
            dst_df = pd.DataFrame(columns=["vid", "ocr"])
    else:
        dst_df = pd.DataFrame(columns=["vid", "ocr"])

    # è·å–å¾…å¤„ç†çš„è§†é¢‘æ–‡ä»¶
    video_files = []
    for file in os.listdir(src_dir):
        if file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
            video_path = os.path.join(src_dir, file)
            video_files.append(video_path)

    print(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")

    # å‡†å¤‡å¾…å¤„ç†ä»»åŠ¡ï¼ˆè¿‡æ»¤å·²å¤„ç†çš„ï¼‰
    tasks = []
    processed_ids = set(dst_df["vid"].values) if not dst_df.empty else set()

    for video_path in video_files:
        video_id = os.path.splitext(os.path.basename(video_path))[0]
        if video_id not in processed_ids:
            tasks.append((video_path, extractor, dst_df, dst_file))

    print(f"éœ€è¦å¤„ç† {len(tasks)} ä¸ªæ–°è§†é¢‘")

    if not tasks:
        print("æ‰€æœ‰è§†é¢‘å·²å¤„ç†å®Œæˆï¼")
        return

    # å¹¶è¡Œå¤„ç†è§†é¢‘
    results = []
    with ProcessPoolExecutor(max_workers=extractor.num_workers) as executor:
        futures = {executor.submit(process_single_video, task): task[0]
                   for task in tasks}

        with tqdm(total=len(tasks), desc="å¤„ç†è§†é¢‘") as pbar:
            for future in as_completed(futures):
                try:
                    video_id, status, ocr_text = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    results.append((video_id, status, ocr_text))

                    # æ›´æ–°è¿›åº¦æ¡
                    pbar.set_postfix({
                        "æˆåŠŸ": len([r for r in results if r[1] == "æˆåŠŸ"]),
                        "å¤±è´¥": len([r for r in results if r[1] == "å¤±è´¥"]),
                        "è·³è¿‡": len([r for r in results if r[1] == "å·²è·³è¿‡"])
                    })
                    pbar.update(1)

                except Exception as e:
                    print(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                    pbar.update(1)

    # ä¿å­˜æˆåŠŸçš„ç»“æœ
    new_records = []
    for video_id, status, ocr_text in results:
        if status == "æˆåŠŸ" and ocr_text:
            new_records.append({"vid": video_id, "ocr": ocr_text})

    if new_records:
        new_df = pd.DataFrame(new_records)
        dst_df = pd.concat([dst_df, new_df], ignore_index=True)

        # ä¿å­˜åˆ°æ–‡ä»¶
        dst_df.to_json(dst_file, orient="records", lines=True, force_ascii=False)
        print(f"\næˆåŠŸå¤„ç† {len(new_records)} ä¸ªè§†é¢‘ï¼Œå·²ä¿å­˜åˆ° {dst_file}")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    success_count = len([r for r in results if r[1] == "æˆåŠŸ"])
    fail_count = len([r for r in results if r[1] == "å¤±è´¥"])
    skip_count = len([r for r in results if r[1] == "å·²è·³è¿‡"])

    print("\n" + "=" * 50)
    print(f"å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"  âœ… æˆåŠŸ: {success_count}")
    print(f"  âŒ å¤±è´¥: {fail_count}")
    print(f"  â­ï¸  è·³è¿‡: {skip_count}")
    print(f"  ğŸ“Š æ€»è®¡: {len(results)}")


if __name__ == "__main__":
    main()
